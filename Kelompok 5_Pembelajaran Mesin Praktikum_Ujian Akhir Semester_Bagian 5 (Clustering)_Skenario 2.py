# -*- coding: utf-8 -*-
"""UAS ML PRAK_SKENARIO 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V5EI7flS12UJC83GPWrRT5dM6HwdZLkO
"""

#-----UAS PEMBELAJARAN MESIN-----#
#BAGIAN 5 CLUSTERING

#SKENARIO KEDUA

#Anggota:
#1. 187231035 / Nicco Cahya Permana
#2. 187231059 / Ahmad Mirza Rafiq Azmi
#3. 187231076 / I Nengah Sutha Dharmendra
#4. 187231081 / Rheinaldy Susanto

#-----UAS PEMBELAJARAN MESIN-----#

#-----Persiapan Tools-----#

# Install Tools yang Diperlukan
!pip install scikit-fuzzy

# Import Tools yang Diperlukan
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans, DBSCAN
from scipy import stats
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import skfuzzy as fuzz
from collections import Counter
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

#-----Persiapan Tools-----#

#-----Persiapan Dataset-----#

# Import Dataset Nanonano
df = pd.read_excel('Nanonano.xlsx')
df.head()

#-----Persiapan Dataset-----#

#-----Preprocessing Data-----#

# Melihat Bentuk Data
df.shape

# Melihat Ringkasan Statistik Data
df.describe()

# Memperbaiki Tipe Data Desimal
kolom_koma = ['C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']

for kolom in kolom_koma:
    df[kolom] = df[kolom].astype(str).str.replace(',', '.', regex=False).astype(float)

# Menampilakn Data Setelah Memperbaiki Tipe Data Desimal
df.head()

# Cek Missing Values Pada Data
df.isna().sum()

# Menangani Missing Values
# Karena tidak ada missing values maka tidak perlu dilakukan penanganan

# Cek Outlier Pada Data
kolom_numerik = ["B", "C", "D", "E", "F", "G", "H", "I", "J", "K"]
z_scores = np.abs(stats.zscore(df[kolom_numerik]))
outliers_z = df[(z_scores > 3).any(axis=1)]
print("Outlier berdasarkan Z-score:\n", outliers_z)

# Menangani Outlier Dengan menghapusnya
df_cleaned = df[(z_scores <= 3).all(axis=1)].copy()
print("Dataset setelah menghapus outlier:\n", df_cleaned)

#-----Preprocessing Data-----#

#-----Encoding-----#

# Melakukan Encoding untuk Kolom Label
label_map = {
    'breakfast': 1,
    'lunch': 2,
    'snack': 3,
    'diner': 4
}
df_cleaned['L'] = df['L'].map(label_map)

# Menampilkan Data Setelah Encoding
print("Dataset setelah menghapus encoding:\n")
df_cleaned.head()

#-----Encoding-----#

#-----Normalisasi-----#

#Melakukan Normalisasi untuk Kolom Numerik (Kolom B - K) Mengggunakan Z-Score Normalization
kolom_fitur = ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']
scaler = StandardScaler()
df_cleaned[kolom_fitur] = scaler.fit_transform(df_cleaned[kolom_fitur])

print("Dataset setelah menghapus normalisasi:\n")
df_cleaned.head()

#-----Normalisasi-----#

#-----Elbow Method-----#

kolom_fitur = ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']

# 1. Cluster Optimal K-Means
# Elbow Method Untuk Mencari Cluster Optimal K-Means
X_all = df_cleaned[kolom_fitur].values
y_all = df_cleaned['L'].values

# Ekstraksi fitur menggunakan LDA
lda = LinearDiscriminantAnalysis(n_components=2)
X_lda = lda.fit_transform(X_all, y_all)

inertia = []
for n in range(1, 11):
    model = KMeans(
        n_clusters=n,
        init='k-means++',
        n_init=10,
        max_iter=300,
        random_state=111
    )
    model.fit(X_all)
    inertia.append(model.inertia_)
plt.figure(figsize=(10, 5))
plt.plot(range(1, 11), inertia, 'o-')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method')
plt.grid(True)
plt.show()

# Mengambil Jumlah Cluster Optimal Berdasarkan Elbow Method
cluster_optimal_kmeans = 2
print(f"Jumlah cluster optimal KMeans: {cluster_optimal_kmeans}")

# 2. Cluster Optimal Fuzzy C-Means
# FCP Plot Untuk Mencari Cluster Optimal Fuzzy C-Means
n_clusters_range = range(2, 11)
fpcs = []

for n_clusters in n_clusters_range:
    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(
        X_all.T,
        c=n_clusters,
        m=2,
        error=0.005,
        maxiter=1000,
        init=None
    )
    fpcs.append(fpc)
plt.figure(figsize=(10, 6))
plt.plot(n_clusters_range, fpcs, 'o-')
plt.xlabel('Number of Clusters')
plt.ylabel('Fuzzy Partition Coefficient (FPC)')
plt.title('FPC to Determine Optimal Number of Clusters (FCM)')
plt.grid(True)
plt.show()

# Mengambil jumlah cluster optimal berdasarkan FPC tertinggi
cluster_optimal_fcm = n_clusters_range[fpcs.index(max(fpcs))]
print(f"Jumlah cluster optimal berdasarkan FPC: {cluster_optimal_fcm}")

# 3. Cluster Optimal DBScan
# K-Distance Graph Untuk Menentukan Nilai Epsilon Optimal
neighbors = NearestNeighbors(n_neighbors=4)
neighbors_fit = neighbors.fit(X_all)
distances, indices = neighbors_fit.kneighbors(X_all)
distances = np.sort(distances[:, 3], axis=0)
plt.figure(figsize=(10, 6))
plt.plot(range(len(distances)), distances)
plt.xlabel('Points sorted by distance')
plt.ylabel('k-distance (k=4)')
plt.title('k-distance Graph for Optimal Epsilon Selection')
plt.grid(True)
plt.show()

# Menentukan nilai epsilon optimal dan minimal sample berdasarkan plot K-Distance
eps_optimal = 2.3
min_samples_db = 3
print(f"Parameter DBScan yang dipilih: eps={eps_optimal}, min_samples={min_samples_db}")

#-----Elbow Method-----#

#-----Clustering-----#

# Inisialisasi dan fit LDA (misalnya mau reduce ke 2 dimensi)
lda = LinearDiscriminantAnalysis(n_components=2)
y_all = df_cleaned['L'].values
X_lda = lda.fit_transform(X_all, y_all)

# 1. K-Means Clustering
# Clustering menggunakan hasil ekstraksi LDA
algorithm_lda = KMeans(
    n_clusters=cluster_optimal_kmeans,
    init='k-means++',
    n_init=10,
    max_iter=300,
    tol=0.0001,
    random_state=111,
    algorithm='elkan'
)
labels_lda = algorithm_lda.fit_predict(X_lda)
centroids_lda = algorithm_lda.cluster_centers_

plt.figure(figsize=(15, 7))
colors = ['blue', 'orange', 'green', 'red', 'purple']

for j in range(cluster_optimal_kmeans):
    plt.scatter(
        X_lda[labels_lda == j, 0],
        X_lda[labels_lda == j, 1],
        c=colors[j],
        s=200,
        alpha=0.7,
        label=f'Cluster {j}'
    )

plt.scatter(
    centroids_lda[:, 0],
    centroids_lda[:, 1],
    c='red',
    marker='o',
    s=300,
    linewidths=3,
    label='Centroids'
)

plt.xlabel('LDA Component 1')
plt.ylabel('LDA Component 2')
plt.title('KMeans Clustering setelah LDA')
plt.legend()
plt.grid(True)
plt.show()

# Evaluasi Silhouette Score
silhouette_lda = silhouette_score(X_lda, labels_lda)
print(f"Silhouette Score K-Means setelah LDA: {silhouette_lda:.4f}")

y_all = df_cleaned['L'].values

# LDA untuk mereduksi fitur ke 2 dimensi
lda = LinearDiscriminantAnalysis(n_components=2)
X_lda = lda.fit_transform(X_all, y_all)

# 2. Fuzzy C-Means Clustering
# Transpose data agar sesuai format input skfuzzy
X_lda_fuzzy = X_lda.T
# Fuzzy C-Means Clustering pada hasil LDA
cntr_lda, u_lda, u0_lda, d_lda, jm_lda, p_lda, fpc_lda = fuzz.cluster.cmeans(
    X_lda_fuzzy,
    c=cluster_optimal_fcm,  # jumlah cluster optimal dari FPC
    m=2,
    error=0.005,
    maxiter=1000,
    init=None
)

# Mendapatkan cluster berdasarkan probabilitas tertinggi
cluster_membership_lda = np.argmax(u_lda, axis=0)

# Visualisasi hasil clustering FCM setelah LDA
plt.figure(figsize=(15, 7))
colors = ['blue', 'orange', 'green', 'red', 'purple']

for j in range(cluster_optimal_fcm):
    plt.scatter(
        X_lda[cluster_membership_lda == j, 0],
        X_lda[cluster_membership_lda == j, 1],
        c=colors[j],
        s=200,
        alpha=0.7,
        label=f'Cluster {j}'
    )

# Centroid dari hasil FCM di ruang LDA
plt.scatter(
    cntr_lda[:, 0],
    cntr_lda[:, 1],
    c='red',
    marker='o',
    s=300,
    linewidths=2,
    label='Centroids'
)

plt.xlabel('LDA Component 1')
plt.ylabel('LDA Component 2')
plt.title('Fuzzy C-Means Clustering setelah LDA')
plt.legend()
plt.grid(True)
plt.show()

# Evaluasi dengan Silhouette Score
silhouette_fcm_lda = silhouette_score(X_lda, cluster_membership_lda)
print(f"Silhouette Score Fuzzy C-Means setelah LDA: {silhouette_fcm_lda:.4f}")

y_all = df_cleaned['L'].values

# LDA untuk mereduksi fitur ke 2 dimensi
lda = LinearDiscriminantAnalysis(n_components=2)
X_lda = lda.fit_transform(X_all, y_all)

# ======== Jalankan DBSCAN dengan eps baru ========
dbscan_lda = DBSCAN(eps=0.4, min_samples=min_samples_db)
# Fit DBSCAN pada hasil LDA
dbscan_labels_lda = dbscan_lda.fit_predict(X_lda)
dbscan_labels_lda = dbscan_lda.fit_predict(X_lda)
# Menghitung jumlah cluster (tidak termasuk noise)
n_clusters_lda = len(set(dbscan_labels_lda)) - (1 if -1 in dbscan_labels_lda else 0)
n_noise_lda = list(dbscan_labels_lda).count(-1)
print(f"Jumlah cluster DBSCAN setelah LDA: {n_clusters_lda}")
print(f"Jumlah noise points: {n_noise_lda}")

# Visualisasi DBSCAN setelah LDA
plt.figure(figsize=(10, 6))
unique_labels = set(dbscan_labels_lda)
colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']

for i in unique_labels:
    if i == -1:
        plt.scatter(
            X_lda[dbscan_labels_lda == i, 0],
            X_lda[dbscan_labels_lda == i, 1],
            s=100,
            c='black',
            label='Noise',
            alpha=0.5
        )
    else:
        plt.scatter(
            X_lda[dbscan_labels_lda == i, 0],
            X_lda[dbscan_labels_lda == i, 1],
            s=200,
            c=colors[i % len(colors)],
            label=f'Cluster {i+1}',
            alpha=0.6
        )
plt.xlabel('LDA Component 1')
plt.ylabel('LDA Component 2')
plt.title(f'DBSCAN setelah LDA (eps=0.4, min_samples={min_samples_db})')
plt.legend()
plt.grid(True)
plt.show()

# Silhouette Score DBSCAN setelah LDA
if n_clusters_lda > 1:
    mask = dbscan_labels_lda != -1
    if np.sum(mask) > 1:
        silhouette_lda_dbscan = silhouette_score(X_lda[mask], dbscan_labels_lda[mask])
        print(f"Silhouette Score DBSCAN setelah LDA: {silhouette_lda_dbscan:.4f}")
    else:
        print("DBSCAN setelah LDA: Tidak cukup data non-noise untuk menghitung silhouette score")
        silhouette_lda_dbscan = -1
else:
    print("DBSCAN setelah LDA: Tidak ada cluster yang terbentuk")
    silhouette_lda_dbscan = -1

#-----Evaluasi (Silhouette Score)-----#
print(f"Silhouette Score K-Means Clustering: {silhouette_lda:.4f}")
print(f"Silhouette Score K-Means Fuzzy C-Means Clustering: {silhouette_fcm_lda:.4f}")
print(f"Silhouette Score DBScan Clustering: {silhouette_lda_dbscan:.4f}")

#-----Evaluasi (Silhouette Score)-----#

#-----Anggota Tiap cluster-----#

# 1. Anggota Cluster K-MeansClustering
print("Anggota Cluster K-Means Clustering:")
df_kmeans = df_cleaned.copy()
df_kmeans['KMeans_Cluster'] = labels_lda
kmeans_clusters = sorted(df_kmeans['KMeans_Cluster'].unique())
for cluster in kmeans_clusters:
  cluster_data = df_kmeans[df_kmeans['KMeans_Cluster'] == cluster]
  print(f"\n--- Cluster {cluster} ({len(cluster_data)} anggota) ---")
  print(cluster_data.head(5).to_string(index=False))

# 2. Anggota Cluster Fuzzy C-Means Clustering
print("Anggota Cluster Fuzzy C-Means Clustering:")
df_fuzzy = df_cleaned.copy()
df_fuzzy['Fuzzy_Cluster'] = cluster_membership_lda
fuzzy_clusters = sorted(df_fuzzy['Fuzzy_Cluster'].unique())
for cluster in fuzzy_clusters:
  cluster_data = df_fuzzy[df_fuzzy['Fuzzy_Cluster'] == cluster]
  print(f"\n--- Cluster {cluster} ({len(cluster_data)} anggota) ---")
  print(cluster_data.head(5).to_string(index=False))

# 3. Anggota Cluster DBScan Clustering
print("Anggota Cluster Fuzzy DBScan Clustering:")
df_dbscan = df_cleaned.copy()
df_dbscan['DBSCAN_Cluster'] = dbscan_labels_lda
if -1 in df_dbscan['DBSCAN_Cluster'].values:
  noise_data = df_dbscan[df_dbscan['DBSCAN_Cluster'] == -1]
  print(f"\n--- Noise Points ({len(noise_data)} anggota) ---")
  print(noise_data.head(5).to_string(index=False))
  print("... (data lengkap ada di file CSV)")
  regular_clusters = [c for c in df_dbscan['DBSCAN_Cluster'].unique() if c != -1]
if regular_clusters:
  for cluster in sorted(regular_clusters):
    cluster_data = df_dbscan[df_dbscan['DBSCAN_Cluster'] == cluster]
    print(f"\n--- Cluster {cluster} ({len(cluster_data)} anggota) ---")
    print(cluster_data.head(5).to_string(index=False))
    print("... (data lengkap ada di file CSV)")
  else:
    print("\nTidak ada cluster yang terbentuk (semua data adalah noise)")

#-----Anggota Tiap cluster-----#

#-----Beri Label Pada Data Cluster-----#

print("Label Clustering Untuk Dataset:")
final_df = df_cleaned.copy()
final_df['KMeans_Cluster'] = labels_lda
final_df['Fuzzy_Cluster'] = cluster_membership_lda
final_df['DBSCAN_Cluster'] = dbscan_labels_lda
print(final_df.head(5).to_string(index=False))

#-----Beri Label Pada Data Cluster-----#